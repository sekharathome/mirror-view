<div id="setup-view" class="live-card">
    <h3 style="margin-top:0; color:#2c3e50;">Live Viewing Setup</h3>
    
    <div style="margin-bottom: 20px;">
        <label>Audio Source:</label><br>
        <select id="audio-opt" style="padding:8px; width:200px; margin-top:5px;">
            <option value="off">No Audio</option>
            <option value="mic">Microphone</option>
            <option value="system">System Audio (Android 10+)</option>
        </select>
    </div>

    <div style="display: flex; justify-content: center; gap: 10px; margin-bottom: 20px;">
        <button class="btn-start" onclick="startStream()" style="flex:2;">â–¶ START SCREEN</button>
        <button onclick="takeShot()" style="flex:1; background:#3498db; color:white; border:none; border-radius:4px; cursor:pointer;">
            <i class="fas fa-camera"></i> SNAPSHOT
        </button>
    </div>

    <div style="border-top: 1px solid #eee; padding-top: 15px;">
        <label style="cursor:pointer;">
            <input type="checkbox" id="record-toggle"> Record this session
        </label>
    </div>
</div>

<script>
    const socket = new WebSocket('wss://mirror-view.onrender.com');
    const canvas = document.getElementById('display');
    const ctx = canvas.getContext('2d');
    let isStreaming = false;

    // AUDIO LOGIC
    let audioCtx = null;
    let nextAudioTime = 0;

    socket.onmessage = (event) => {
        const data = event.data;

        // 1. Render Video Frames
        if (data.startsWith("FRAME:") && isStreaming) {
            const img = new Image();
            img.onload = () => {
                canvas.width = img.width;
                canvas.height = img.height;
                ctx.drawImage(img, 0, 0);
            };
            img.src = "data:image/jpeg;base64," + data.substring(6);
        }

        // 2. Play Audio Chunks
        else if (data.startsWith("AUDIO:")) {
            playPcmChunk(data.substring(6));
        }

        // ... Status and Log handling ...
    };

    function playPcmChunk(base64) {
        if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        
        // Convert Base64 to ArrayBuffer
        const binary = atob(base64);
        const bytes = new Int16Array(binary.length / 2);
        for (let i = 0; i < bytes.length; i++) {
            bytes[i] = (binary.charCodeAt(i * 2) & 0xFF) | (binary.charCodeAt(i * 2 + 1) << 8);
        }
        
        const buffer = audioCtx.createBuffer(1, bytes.length, 44100);
        const channelData = buffer.getChannelData(0);
        for (let i = 0; i < bytes.length; i++) {
            channelData[i] = bytes[i] / 32768.0; // PCM16 to Float32
        }

        const source = audioCtx.createBufferSource();
        source.buffer = buffer;
        source.connect(audioCtx.destination);
        
        const startTime = Math.max(audioCtx.currentTime, nextAudioTime);
        source.start(startTime);
        nextAudioTime = startTime + buffer.duration;
    }

    function startStream() {
        const audio = document.getElementById('audio-opt').value;
        const record = document.getElementById('record-toggle').checked;
        
        // Send enhanced command to server
        socket.send(`START_SCREEN:${audio}:${record}`);
        
        document.getElementById('setup-view').style.display = 'none';
        document.getElementById('stream-view').style.display = 'block';
        isStreaming = true;
    }
    // ... existing stopStream and takeShot functions ...
</script>
